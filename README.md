# PredicciÃ³n de Supervivencia en el Titanic

Este proyecto busca predecir la supervivencia de pasajeros del Titanic mediante tÃ©cnicas de anÃ¡lisis de datos, modelado supervisado y no supervisado, asÃ­ como estrategias hÃ­bridas. EstÃ¡ dirigido a analistas, cientÃ­ficos de datos y estudiantes interesados en aplicar machine learning en contextos histÃ³ricos y narrativos.

##  IntroducciÃ³n

Se realizÃ³ un proceso completo de ETL para limpiar el dataset, imputar valores nulos, crear nuevas variables y codificar variables categÃ³ricas. El anÃ¡lisis exploratorio (EDA) revelÃ³ patrones en sexo, edad, clase y tarifas. Se aplicaron modelos supervisados como RegresiÃ³n LogÃ­stica, Random Forest, KNN y SVM, y un anÃ¡lisis no supervisado con K-means (K=4) para segmentar pasajeros e interpretar arquetipos. Finalmente, se evaluaron estrategias hÃ­bridas:  
- **Ruta A**: Mixture of Experts  
- **Ruta B**: ClÃºster como feature adicional

##  AnÃ¡lisis Exploratorio

- 38.3% de los pasajeros sobreviviÃ³  
- Las mujeres y los niÃ±os tuvieron mayor probabilidad de supervivencia  
- Los pasajeros de 1Âª clase presentaron ventajas claras frente a 2Âª y 3Âª clase

##  Modelado Supervisado (Baseline)

Se aplicaron cuatro modelos supervisados. El desempeÃ±o se resume a continuaciÃ³n:

| Modelo               | Accuracy | Precision | Recall  | AUC    |
|----------------------|----------|-----------|---------|--------|
| RegresiÃ³n LogÃ­stica  | 0.8338   | 0.7998    | 0.7571  | 0.8696 |
| Random Forest        | 0.8114   | 0.7642    | 0.7369  | 0.8623 |
| KNN                  | 0.8159   | 0.7925    | 0.7047  | 0.8622 |
| SVM                  | 0.8100   | 0.8100    | 0.6800  | 0.8370 |

##  ComparaciÃ³n de Modelos

- RegresiÃ³n LogÃ­stica destaca por su AUC (â‰ˆ0.87)  
- SVM logra mayor precisiÃ³n  
- Las matrices de confusiÃ³n muestran fortalezas distintas: algunos modelos priorizan detecciÃ³n de no sobrevivientes, otros balance entre clases  
- Las curvas ROC confirman buen rendimiento general (AUC > 0.8)

##  AnÃ¡lisis No Supervisado (K-means)

Se aplicÃ³ K-means (K=4) para segmentar pasajeros en clÃºsteres con perfiles diferenciados:

- **ClÃºster 3**: Mujeres de clase media con alta supervivencia (â‰ˆ79%)  
- **ClÃºster 1**: Hombres mayores de 1Âª clase con supervivencia intermedia (â‰ˆ47%)  
- **ClÃºster 2**: Familias numerosas de 3Âª clase con supervivencia baja-intermedia (â‰ˆ44%)  
- **ClÃºster 0**: Hombres jÃ³venes de 3Âª clase con baja supervivencia (â‰ˆ26%)

##  Estrategias HÃ­bridas

Se probaron dos enfoques:

| Modelo                          | Accuracy | Precision | Recall  | AUC    |
|----------------------------------|----------|-----------|---------|--------|
| Ruta A (Mixture of Experts)      | 0.7877   | 0.7460    | 0.6811  | 0.7678 |
| Ruta B (Cluster como feature)    | 0.8305   | 0.7961    | 0.7513  | 0.8695 |

- Ruta B mantiene mÃ©tricas similares al baseline  
- Ruta A degrada el rendimiento por menor capacidad de generalizaciÃ³n en subgrupos

##  Consideraciones TÃ©cnicas

- Se detectÃ³ fuga de datos por imputaciones y clustering global  
- Se recomienda encapsular todo el preprocesamiento en un pipeline y recalcular por fold en cada split/CV

##  Conclusiones

- Sexo, edad y clase social fueron factores clave en la supervivencia  
- RegresiÃ³n LogÃ­stica fue el mejor modelo por AUC  
- El clustering aportÃ³ interpretabilidad pero no mejorÃ³ mÃ©tricas  
- Se confirma la regla histÃ³rica: â€œMujeres y niÃ±os primero, especialmente de clases altasâ€

---

ğŸ“Œ *Este proyecto es una demostraciÃ³n prÃ¡ctica de cÃ³mo combinar anÃ¡lisis exploratorio, modelado predictivo y segmentaciÃ³n para entender fenÃ³menos histÃ³ricos desde una perspectiva de ciencia de datos.*
